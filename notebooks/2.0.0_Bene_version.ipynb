{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3225,"status":"ok","timestamp":1651491950102,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"QNMg8GXIW5iB","outputId":"9a81ef29-470e-4428-dc82-0078ed03992c"},"outputs":[],"source":["cd /Users/XX/ZoRaFa/yolov5_train_test\n","# Replace the XX in file paths. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12678,"status":"ok","timestamp":1651491962772,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"EKvOM0KIZrhw","outputId":"9d862f03-8646-46f5-91f3-9e2e928dbbf0"},"outputs":[],"source":["pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3337,"status":"ok","timestamp":1651478888204,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"HEtGDn9gZ9Iv"},"outputs":[],"source":["import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from pycocotools.coco import COCO\n","import pandas as pd\n","import random\n","from PIL import Image, ImageDraw, ImageFont, ExifTags\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import matplotlib.patches as patches\n","from matplotlib.pyplot import figure\n","from shapely.geometry import Polygon\n","import pylab\n","pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n","import cv2\n","import os\n","import datetime\n","import torch\n","import torchvision"]},{"cell_type":"markdown","metadata":{"id":"0nHJrSScWv5a"},"source":["we have that the \n","- coco : common objects in context, a way to do object detection using json sstructuure which determines how the labels are annotated\n","- pycocotools: helps doig the parsing ..."]},{"cell_type":"markdown","metadata":{"id":"4_zNEamkW2P7"},"source":["## Load Data\n","### CSV Files from SharePoints (Images/BBOXES)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd /Users/XX/Documents/surfrider/surfnet/data/images/annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2928,"status":"ok","timestamp":1651479113300,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"oxK4Dl2BcGh9"},"outputs":[],"source":["df_bboxes = pd.read_csv(\"bounding_boxes_202205231416.csv\")\n","df_images = pd.read_csv(\"images_for_labelling_202205231708.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1651479113301,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"DE35ZqV8c2oR","outputId":"3eff11aa-3d03-4a8b-8749-384475827842"},"outputs":[],"source":["df_images.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1651479798440,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"-fZT4PIZiXeJ","outputId":"08a89c94-20ab-4ec6-b51a-80f47b365b37"},"outputs":[],"source":["print(f'Nb. of bboxes : {len(df_bboxes)}')\n","print(f'Nb. of images : {len(df_images)}')"]},{"cell_type":"markdown","metadata":{"id":"KZb8cgzxW-HP"},"source":["I believe we have that there is the images; with different caracteristics, such as the type of view that there is, the nagle of the pic, the quality and the context - the water source/type \n","\n","Then there is the bonding box, each one is linked to an image ; and has 4 coordinates which determine sthe box. There is also the class ID : with the type of pollution detected (0) -10 "]},{"cell_type":"markdown","metadata":{"id":"HkN5YL2biqqX"},"source":["### Instances Files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1912,"status":"ok","timestamp":1651479803421,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"r3GUFaW4ilVK","outputId":"a202919f-c900-4bd0-a027-c877d4ac1acb"},"outputs":[],"source":["coco_train  = COCO(annotation_file = 'instances_train.json')\n","coco_valid  = COCO(annotation_file = 'instances_val.json')\n","coco_images = COCO(annotation_file = 'instances.json')\n","\n","coco_images_train = coco_train.dataset['images'][1:]\n","coco_images_valid = coco_valid.dataset['images'][1:]\n","coco_images       = coco_images.dataset['images'][1:]"]},{"cell_type":"markdown","metadata":{"id":"92tO5MfpXFtU"},"source":["Here we have that the COCO loads the annotation file and prepare data structure"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'Nb. of train images : {len(coco_images_train)}')\n","print(f'Nb. of val.  images : {len(coco_images_valid)}')\n","print(f'Nb. of total images : {len(coco_images)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42881,"status":"ok","timestamp":1651479853094,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"JOnszVSsisrh"},"outputs":[],"source":["IMAGES_PATH = \"images2label\"\n","images      = os.listdir(IMAGES_PATH)\n","images_full_path = [os.path.join(IMAGES_PATH, x) for x in os.listdir(IMAGES_PATH)]\n","\n","print(f'Image Path : {len(images)}')"]},{"cell_type":"markdown","metadata":{"id":"TaL1-V8EXKn1"},"source":["## Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1651479862651,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"WG5peqkx1ALf","outputId":"48cc9978-d4a0-4103-f923-749e2a0c1e4d"},"outputs":[],"source":["filenames = list(df_images.filename.unique())\n","len(filenames)\n","# here we're taking the files that are unique : so got rid of the doubles"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1651479864324,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"-RJGmrMv1IQW","outputId":"0d9bcb71-8668-4a5c-c272-8228eb145657"},"outputs":[],"source":["filenames_train = [obj['file_name'] for obj in coco_images_train]\n","filenames_valid = [obj['file_name'] for obj in coco_images_valid]\n","print(\"TRAIN\", len(filenames_train), \"VALID\", len(filenames_valid))\n","filenames_train_valid = filenames_train + filenames_valid\n","print(\"TOTAL\", len(filenames_train_valid))\n","\n","#here we have the total train and validity is of 3921 and then the rest would be the one who \n","#are on the csv file but not on the instances\n","# we have that we divided our images into 2 sets one for training and one for validation "]},{"cell_type":"markdown","metadata":{"id":"EO20e0AKXZtE"},"source":["### Files included in CSV and Instances"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1651479866978,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"fEW_ZiXm1Tjy","outputId":"692de20f-1e84-4552-c0e2-3b130166f5ec"},"outputs":[],"source":["files_inter = list(set(filenames) & set(filenames_train_valid))\n","len(files_inter)"]},{"cell_type":"markdown","metadata":{"id":"rZrTN4Xn1WTR"},"source":["### Files that are CSV but not instances "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1651479869908,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"2HaSZzLe1ZtY","outputId":"14911353-ec8a-4f15-b0cb-c540acb32000"},"outputs":[],"source":["set_difference_f = set(filenames) - set(filenames_train_valid)\n","list_difference_f = list(set_difference_f)\n","len(list_difference_f)"]},{"cell_type":"markdown","metadata":{"id":"a7yuUYZO1_Cj"},"source":["### Names of the files of the Instances that are not in CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1651479872275,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"7KamaQ9U1_xT","outputId":"0a70071f-a708-44b2-eee2-cd01b459ad09"},"outputs":[],"source":["set_difference_i = set(filenames_train_valid) - set(filenames)\n","list_difference_i = list(set_difference_i)\n","len(list_difference_i)"]},{"cell_type":"markdown","metadata":{"id":"pWoUcOCuXkhC"},"source":["### GroupBy ID"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd /Users/XX/ZoRaFa/yolov5_train_test/src/surfnet_train/visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from categories import annotations_cat\n","annotations_cat(df_bboxes);"]},{"cell_type":"markdown","metadata":{"id":"ZrEJKK-rYMkK"},"source":["the data is unbalanced - way more of categpry 1 : sheet, tarp, plastic bags and fragment \n","- Sheet / tarp / plastic bag / fragment\n","- Insulating material\n","- Bottle-shaped\n","- Can-shaped\n","- Drum\n","- Other packaging\n","- Tire\n","- Fishing net / cord\n","- Easily namable\n","- Unclear"]},{"cell_type":"markdown","metadata":{"id":"Mjc7IBB7YMxA"},"source":["### GroupBy Context"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from categories import img_context\n","img_context(df_images);"]},{"cell_type":"markdown","metadata":{"id":"Bhxrtt07YZu8"},"source":["The data is unbalanced : once again much more of the river then others ; small beach"]},{"cell_type":"markdown","metadata":{"id":"XgTg9PgFYcxL"},"source":["### GroupBy View"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from categories import img_view\n","img_view(df_images);"]},{"cell_type":"markdown","metadata":{"id":"YPG7HHg7YhyY"},"source":["### GroupBy Image quality"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651479879421,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"H7zmA7jZYkyO","outputId":"c51bf84c-19b0-4a6d-c20f-75ea7c81b9ce"},"outputs":[],"source":["from categories import img_quality\n","img_quality(df_images);"]},{"cell_type":"markdown","metadata":{"id":"iT1fW9W5YoJz"},"source":["## Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd /Users/XX/ZoRaFa/yolov5_train_test/src/surfnet_train/data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data_processing import coco2yolo\n","from data_processing import get_df_train_val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1651234055684,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"bkdqLbtC49un","outputId":"a99690f1-3e34-4a7f-e03f-460003669267"},"outputs":[],"source":["!mkdir ./images\n","!mkdir ./labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd /Users/XX/ZoRaFa/yolov5_train_test/src/surfnet_train/models "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import path_existance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_df_train_val(\"/Users/XX/Documents/surfrider/surfnet/data/images/annotations/instances.json\", \"/Users/XX/Documents/surfrider/surfnet/data/images/annotations/images2label\" , df_images)"]},{"cell_type":"markdown","metadata":{"id":"HQlQ7krqYwaY"},"source":["### Get Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1651479969514,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"tfKO7En75AJC","outputId":"3418c828-47a7-4e7e-efc1-70af3bc81655"},"outputs":[],"source":["annotation_file = \"annotations-surfnet/instances_train.json\"\n","coco = COCO(annotation_file)\n","\n","coco_categories = coco.dataset['categories'][1:]\n","class_id_to_name_mapping = {}\n","for c in coco_categories:\n","    class_id_to_name_mapping[c['id']-1] = c['name']\n","\n","class_id_to_name_mapping"]},{"cell_type":"markdown","metadata":{"id":"ENgoEjKNY04B"},"source":["### Creation of 2 DataFrames for future manipulation 5GrouppKFold, KFold, Split)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuhaceHG5EVm","outputId":"b4f68f65-bee5-4e6e-f6c3-ae017de120b3"},"outputs":[],"source":["data_dir = \"images2label\"\n","\n","def get_df_train_val(annotation_file):\n","    \n","    coco = COCO(annotation_file) #transform the file \n","\n","    old_filenames  = []\n","    dates          = []\n","    views          = []\n","    images_quality = []\n","    contexts       = []\n","    all_bboxes     = []\n","    all_images     = []\n","    new_filenames  = []\n","    new_labelnames = []\n","\n","    img_ids = np.array(coco.getImgIds())\n","    \n","    for img_id in img_ids:\n","        image_infos = coco.loadImgs(ids=[img_id])[0]\n","\n","        if os.path.exists(os.path.join(data_dir, image_infos['file_name'])):\n","\n","            date_creation  = df_images.loc[df_images[\"filename\"] == image_infos[\"file_name\"]][\"createdon\"].values[0]\n","            view           = df_images.loc[df_images[\"filename\"] == image_infos[\"file_name\"]][\"view\"].values[0]\n","            image_quality  = df_images.loc[df_images[\"filename\"] == image_infos[\"file_name\"]][\"image_quality\"].values[0]\n","            context        = df_images.loc[df_images[\"filename\"] == image_infos[\"file_name\"]][\"context\"].values[0]\n","\n","            date_time_obj = datetime.datetime.strptime(date_creation, '%Y-%m-%d %H:%M:%S')\n","\n","            old_filenames.append(image_infos[\"file_name\"])\n","            dates.append(date_time_obj)\n","            views.append(view)\n","            images_quality.append(image_quality)\n","            contexts.append(context)\n","\n","            image = Image.open(os.path.join(data_dir,image_infos['file_name']))\n","            try:\n","                for orientation in ExifTags.TAGS.keys():\n","                    if ExifTags.TAGS[orientation]=='Orientation':\n","                        break\n","                exif = image._getexif()\n","                if exif is not None:\n","                    if exif[orientation] == 3:\n","                        image=image.rotate(180, expand=True)\n","                    elif exif[orientation] == 6:\n","                        image=image.rotate(270, expand=True)\n","                    elif exif[orientation] == 8:\n","                        image=image.rotate(90, expand=True)\n","\n","            except (AttributeError, KeyError, IndexError):\n","                # cases: image don't have getexif\n","                pass\n","\n","            image    = np.array(image) #cv2.cvtColor(np.array(image.convert('RGB')),  cv2.COLOR_RGB2BGR)\n","            ann_ids  = coco.getAnnIds(imgIds=[img_id])\n","            anns     = coco.loadAnns(ids=ann_ids)\n","            h, w     = image.shape[:-1]\n","            target_h = 1080\n","            ratio    = target_h/h\n","            target_w = int(ratio*w) \n","            image    = cv2.resize(image,(target_w,target_h))\n","            h, w     = image.shape[:-1]\n","            yolo_annot = []\n","            for ann in anns:\n","                cat = ann['category_id'] - 1\n","                [bbox_x, bbox_y, bbox_w, bbox_h] = (ratio*np.array(ann['bbox'])).astype(int)\n","                bbox = np.array([bbox_x, bbox_y, bbox_w, bbox_h])\n","                yolo_bbox = coco2yolo(bbox, target_h, target_w)\n","                yolo_str  = str(cat) + \" \" + \" \".join(yolo_bbox.astype(str))\n","                yolo_annot.append(yolo_str)\n","            \n","            basename  = os.path.splitext(image_infos['file_name'])[0]\n","            file_name = str(image_infos['id']) + \"-\" + basename\n","\n","            img_file_name   = os.path.join(\"./images\", file_name) + \".jpg\"\n","            label_file_name = os.path.join(\"./labels\", file_name) + \".txt\"\n","            \n","            # Save Label\n","            with open(label_file_name, 'w') as f:\n","                f.write('\\n'.join(yolo_annot))\n","\n","            img_to_save = Image.fromarray(image)\n","            # Save image\n","            img_to_save.save(img_file_name)\n","\n","            all_bboxes.append(yolo_annot)\n","            new_filenames.append(img_file_name)\n","            new_labelnames.append(label_file_name)\n","            all_images.append(img_to_save)\n","            \n","    my_list = list(zip(old_filenames, dates, views, images_quality, contexts, new_filenames, new_labelnames, all_images, all_bboxes))\n","    my_df   = pd.DataFrame(my_list, columns=['old_path', 'date', 'view', 'quality','context', 'img_name', 'label_name', 'img', 'bboxes'])\n","    \n","    return my_df\n","\n","df_train = get_df_train_val(\"annotations-surfnet/instances_train.json\")\n","df_valid = get_df_train_val(\"annotations-surfnet/instances_val.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651478857488,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"1-qk8KRCli66","outputId":"a2038f21-f387-4746-f0c4-7afb8b116355"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","#code to see if using the GPU ; helps for the error cuda but only until 50 epochs"]},{"cell_type":"markdown","metadata":{"id":"96u7QE_-Sps2"},"source":["### Group DataFRames for future manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":192,"status":"ok","timestamp":1651237682895,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"OpGlD6lXSqdm","outputId":"b6daa64b-0162-433b-abc2-5b6b89b59572"},"outputs":[],"source":["print(len(df_train))\n","print(len(df_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1651237685806,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"sph1Veft5jNv","outputId":"ec1c5a42-ec4d-4313-cc37-a9024a043fd4"},"outputs":[],"source":["frames = [df_train, df_valid]\n","df_train_valid = pd.concat(frames)\n","\n","df_train_valid.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1651237695060,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"uhseL9Ox9dan","outputId":"7c945009-565c-4653-9041-be11dfbe196a"},"outputs":[],"source":["d = df_train_valid.iloc[0][\"date\"]\n","def get_day(d):\n","    d = d.date()\n","    return int(\"\".join(str(d).split(\"-\")))\n","\n","df_train_valid[\"day\"] = df_train_valid[\"date\"].apply(lambda x: get_day(x))\n","df_train_valid.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1651237714744,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"w3Ndu4ifb76D","outputId":"8d7f9ff5-2030-4ddc-df25-4b97fb69c80c"},"outputs":[],"source":["print(len(df_train_valid))"]},{"cell_type":"markdown","metadata":{"id":"28gvKS6MZQ8X"},"source":["### Simple Kfold\n","Cross-validation, evaluate the model on data sample \n","k : nb of groups the data splits into ; \n","- it shuffles the data; splits it into k groups ; one of them becomes the test and the others become the train sets. We fit the model on the training sets\n","- we use the mean as a test metric\n","\n","k is usually 5 or 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"executionInfo":{"elapsed":1298,"status":"ok","timestamp":1651237724289,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"sb2WKRRg9t1O","outputId":"d246a10f-3263-4f22-c9a2-999ddf9c5480"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=7)\n","df_train_valid = df_train_valid.reset_index(drop=True)\n","df_train_valid['fold'] = -1\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(df_train_valid)):\n","    df_train_valid.loc[val_idx, 'fold'] = fold\n","\n","display(df_train_valid.fold.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1651237729922,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"C6zpmnz39xyU","outputId":"df51f8bc-8096-4370-f42b-23013f074c58"},"outputs":[],"source":["FOLD = 1\n","\n","train_files = []\n","val_files   = []\n","train_df = df_train_valid.query(\"fold!=@FOLD\")\n","valid_df = df_train_valid.query(\"fold==@FOLD\")\n","\n","train_files = list(train_df[\"img_name\"].unique())\n","val_files   = list(valid_df[\"img_name\"].unique())\n","len(train_files), len(val_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1651237734005,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"-fCPaPOQZbyV","outputId":"e4e8cce3-9bcb-4ca0-f92e-0141f31b5834"},"outputs":[],"source":["print(\"Train\", 100 * len(train_files)/(len(train_files)+len(val_files)))\n","print(\"Valid\", 100 * len(val_files)/(len(train_files)+len(val_files)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kJVhzfn91pO"},"outputs":[],"source":["def plot_image_an_bboxes_yolo(image, annotation_list):\n","    annotations = np.array(annotation_list)\n","    w, h = image.size\n","    \n","    plotted_image = ImageDraw.Draw(image)\n","\n","    transformed_annotations = np.copy(annotations)\n","    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n","    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n","    \n","    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n","    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n","    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n","    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n","    \n","    for ann in transformed_annotations:\n","        obj_cls, x0, y0, x1, y1 = ann\n","        plotted_image.rectangle(((x0,y0), (x1,y1)), outline=\"#ff8300\", width=5)\n","        \n","        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n","    \n","    plt.figure(figsize = (12,10))\n","    plt.imshow(np.array(image))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"elapsed":1508,"status":"ok","timestamp":1651237742653,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"InNgdQxK96DF","outputId":"4532d620-cfd6-4f7d-e9a8-c2daa5d6e4b1"},"outputs":[],"source":["row        = df_train_valid.iloc[282]\n","img_name   = os.path.join(\"images-surfnet/images2label\", row[\"old_path\"])\n","img        = row[\"img\"]\n","label_list = row[\"bboxes\"]\n","label_list = [x.split(\" \") for x in label_list]\n","label_list = [[float(y) for y in x ] for x in label_list]\n","\n","plot_image_an_bboxes_yolo(img, label_list)"]},{"cell_type":"markdown","metadata":{"id":"8U7ynCy0ZhT9"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":905,"status":"ok","timestamp":1651237746499,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"AuAQ_vT29-Cg","outputId":"ccb19a61-7112-4c3c-a7ec-10a8c1e85b1b"},"outputs":[],"source":["import yaml\n","\n","cwd = './'\n","\n","with open(os.path.join( cwd , 'train.txt'), 'w') as f:\n","    for path in train_files:\n","        f.write(path+'\\n')\n","            \n","with open(os.path.join(cwd , 'val.txt'), 'w') as f:\n","    for path in val_files:\n","        f.write(path+'\\n')\n","\n","data = dict(\n","    path  = './../',\n","    train =  os.path.join( cwd , 'train.txt') ,\n","    val   =  os.path.join( cwd , 'val.txt' ),\n","    nc    = 10,\n","    names = ['Sheet / tarp / plastic bag / fragment', 'Insulating material', 'Bottle-shaped', 'Can-shaped', 'Drum', 'Other packaging', 'Tire', 'Fishing net / cord', 'Easily namable', 'Unclear'],\n","    )\n","\n","with open(os.path.join( cwd , 'data.yaml'), 'w') as outfile:\n","    yaml.dump(data, outfile, default_flow_style=False)\n","\n","f = open(os.path.join( cwd , 'data.yaml'), 'r')\n","print('\\nyaml:')\n","print(f.read())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1651136506065,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"tgbKkp4_-v8O","outputId":"ff3c4cd0-be49-4b6a-a465-30996916609f"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1651237752046,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"TRSnMp4Y-HKK","outputId":"277c61b5-202b-4ecf-bc35-c9b811169243"},"outputs":[],"source":["%%writefile yolov5/data/hyps/hyp.scratch.yaml\n","\n","# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license\n","# Hyperparameters for COCO training from scratch\n","# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n","# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n","\n","lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n","momentum: 0.937  # SGD momentum/Adam beta1\n","weight_decay: 0.0005  # optimizer weight decay 5e-4\n","warmup_epochs: 3.0  # warmup epochs (fractions ok)\n","warmup_momentum: 0.8  # warmup initial momentum\n","warmup_bias_lr: 0.1  # warmup initial bias lr\n","box: 0.05  # box loss gain\n","cls: 0.5  # cls loss gain\n","cls_pw: 1.0  # cls BCELoss positive_weight\n","obj: 1.0  # obj loss gain (scale with pixels)\n","obj_pw: 1.0  # obj BCELoss positive_weight\n","iou_t: 0.20  # IoU training threshold\n","anchor_t: 4.0  # anchor-multiple threshold\n","# anchors: 3  # anchors per output layer (0 to ignore)\n","fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n","hsv_h: 0.012  # image HSV-Hue augmentation (fraction)\n","hsv_s: 0.6  # image HSV-Saturation augmentation (fraction)\n","hsv_v: 0.3  # image HSV-Value augmentation (fraction)\n","degrees: 2.0  # image rotation (+/- deg)\n","translate: 0.3  # image translation (+/- fraction)\n","scale: 0.25  # image scale (+/- gain)\n","shear: 0.0  # image shear (+/- deg)\n","perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n","flipud: 0.1  # image flip up-down (probability)\n","fliplr: 0.5  # image flip left-right (probability)\n","mosaic: 0.7  # image mosaic (probability)\n","mixup: 0.0  # image mixup (probability)\n","copy_paste: 0.0  # segment copy-paste (probability)"]},{"cell_type":"markdown","metadata":{"id":"DnsdBSFDZnlz"},"source":["A model trained with higher resolution images can have better results for detecting small objects"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2453590,"status":"ok","timestamp":1651240248550,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"V5ngYYvUcKFb","outputId":"cd720ebc-acd5-48cf-c826-de207a46e39f"},"outputs":[],"source":["!python \"yolov5/train.py\" --img 640 --hyp \"yolov5/data/hyps/hyp.scratch.yaml\" --batch 32 --epochs 30 --data \"data.yaml\" --weights \"yolov5s.pt\" --workers 23 --project \"ben\" --name \"yolo_ben_30_I&L\" --exist-ok "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1651243989883,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"EWsqlyh9z4ir","outputId":"bd3fa413-69aa-417e-d133-ebe313c33deb"},"outputs":[],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1668186,"status":"ok","timestamp":1651050674798,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"QLbHj7F1-MlH","outputId":"d0e3759c-edd4-49e9-950b-32746e256527"},"outputs":[],"source":["!python \"yolov5/train.py\" --img 640 --hyp \"yolov5/data/hyps/hyp.scratch.yaml\" --batch 20 --epochs 30 --data \"data.yaml\" --weights \"yolov5s.pt\" --workers 23 --project \"ben\" --name \"yolo_ben_1\" --exist-ok "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651139014510,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"X3zw2u_ZcTyC","outputId":"3c78a602-00ab-44d6-b0e8-6fc88c3af3bf"},"outputs":[],"source":["!python \"yolov5/train.py\" --img 640 --hyp \"yolov5/data/hyps/hyp.scratch.yaml\" --batch 64 --epochs 100 --data \"data.yaml\" --weights \"yolov5s.pt\" --workers 23 --project \"ben\" --name \"yolo_ben_100\" --exist-ok --device 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6706,"status":"ok","timestamp":1651137896541,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"P35OOren_A3V","outputId":"6962ec57-4793-4b70-ff85-6039d5ea034c"},"outputs":[],"source":["!python \"yolov5/train.py\" --img 640 --hyp \"yolov5/data/hyps/hyp.scratch.yaml\" --batch 32 --epochs 50 --data \"data.yaml\" --weights \"yolov5s.pt\" --workers 23 --project \"ben\" --name \"yolo_ben_2\" --exist-ok  --device 0"]},{"cell_type":"markdown","metadata":{"id":"hw2_Y5g8bJF4"},"source":["add smthg to device ; une des variables pas dans le GPU "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1650885046561,"user":{"displayName":"benedicte rispal","userId":"05322587411457809937"},"user_tz":-120},"id":"Aor8lM2M_HZ_","outputId":"646582bc-e27b-431c-b097-b7ec845d18d3"},"outputs":[],"source":["!python \"yolov5/train.py\" --img 640 --hyp \"yolov5/data/hyps/hyp.scratch.yaml\" --batch 32 --epochs 10 0 --data \"data.yaml\" --weights \"yolov5s.pt\" --workers 23 -"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMm6b8R2P9g1UcZQUsNTsC/","collapsed_sections":[],"machine_shape":"hm","name":"My_Yolov5.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
